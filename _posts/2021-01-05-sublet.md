---
Layout: post
mathjax: true
comments: true
title:  "Sublets: a road trip game"
categories: [Mathematics, Programming]
date:  2021-01-05
---

**January 5, 2021.** *Sublets is a fun game for road trips. Take
  letters from the license plates of passing cars, and find words of
  which the license plate letters form a subsequence. I explain the
  game in more detail and provide code for finding solutions. I also
  explore how the difficulty of the game varies with license plate length.*

#### Introduction

*Sublets* (standing for "subsequence of letters") is a game that, to
the best of my knowledge, my family collectively invented on a car
trip to South Australia in the noughties.
In my home state of Victoria, Australia,
license plates used to be alphanumeric strings consisting of three
letters and three numbers.
The game was simply to find a word in which those three letters
occurred, and in
that order.
In mathematical parlance, the license plate letters are a subsequence
of the word.
Here is an example:

$$
\mathbf{spf} \to \mathbf{sp}\text{oo}\mathbf{f}.
$$

The first person to find a valid word wins the round.
The way we played it, if a tie breaker was needed, shorter and/or
simpler words were preferred, so "**sp**oo**f**" beat "**s**o**p**ori**f**ic".

#### A solver

I've written a little solver to find solutions.
It's based on the Natural Language ToolKit (NLTK) package for Python,
and in particular, the `words` corpus, consisting of $\sim 250,000$
English words.
It also uses an iterator trick from the `itertools` library, so we
start by invoking these two packages.
We also download the corpus:

```python
import nltk
import itertools

nltk.download('words')
from nltk.corpus import words
```

Our next step is to define a helper function `subseq(str1, str2)`
which checks if `str2` is a subsequence of `str1`.
It defines an iterator `it` over the letters in `str2`, and then
returns `True` if each letter of the iterator is in `str2`.
The ordering comes for free from the iterator:

```python
def subseq(str1, str2):
  it = iter(str2)
  return all(x in it for x in str1)
```

Finally, for a given license plate string, `sublets(str)` simply
searches the whole corpus `words.words()` and looks for supersequences:

```python
def sublets(str):
    return [word for word in words.words()
		if subseq(str, word)]
```

Note that the `words` corpus is in lowercase.
As an example, we can list words of seven letters or less for which
"spf" is a subsequence:

```python
>>> [word for word in sublets('spf') if len(word) < 8]
['sapful', 'scupful', 'shipful', 'shopful', 'skepful', 
	'specify', 'spiff', 'spiffed', 'spiffy',
	'spitful',  'spoffle', 'spoffy', 'spoof',
	'spoofer', 'spuffle', 'stupefy']
```

Incidentally, this shows that "spoof" is the equal shortest word.
In general, we can find the shortest word with `subletshort(str)`. It does two passes through
the whole list: one to find the minimum length, and a second to pluck
out all the words of that length.

```python
def subletshort(str):
    words = sublets(str)
    minlength = min([len(word) for word in words])
    return [word for word in words if len(word) == minlength]
```

An example:

```python
>>> subletshort("pwm")
['pewdom']
```

Apparently, "pewdom" refers to the "system or prevalence of pews in a
church". English is a funny language.

#### Difficulty scaling

With three letters, the game is often hard, but the chances are very
good that a word would eventually be found, and the natural variation
of difficulty makes the game fun.
At some point, license plates in Victoria shifted to four letters, and
it became much, much harder to play.
This raises the question: how much harder is it to play?
The natural measure is simply how many combinations have answers.
To compute this, we're going to iterate over many combinations of
letters and many words.
We will need to be clever about how we do this in order to have
something that runs in a reasonable time.
To begin with, we don't need all the words in the list, just a check
if it is non-empty.
So we can write a function `subletcheck(str)` which stops iterating over
the corpus and spits out `True` as soon as it finds a single supersequence:

```python
def subletcheck(str):
    outcome = False
    wordnum = len(words.words())
    i = 0
    while outcome == False & i < wordnum:
        outcome = subseq(str, words.words()[i])
        i = i + 1
    return outcome
```

We can use this to build a function `goodlets(n)` which returns the
list of strings of length `n` which have valid supersequences.
Rather than iterate over combinations and then words, it iterates over
words, adding all the subsequences of length $n$ once again using `itertools`:

```python
def goodlets(n):
    goodlet = set()
    for word in words.words():
        lower = [combos for combos in
		list(itertools.combinations(word, n)) if
		all(x.islower() for x in list(combos))]
        goodlet.update(set(lower))
    return goodlet
```

Assuming license plates are random strings of length `n`, then the
chance of success is given by the proportion of good strings to the
total number:

```python
def subletprop(n):
    return len(goodlets(n))/float(26**n)
```

So, let's check how hard it is!
I did up to six letters before my CPU got sore:

```python
>>> [subletprop(2), subletprop(3), subletprop(4), subletprop(5), subletprop(6)]
[1.0, 0.9442, 0.6683, 0.2902, 0.0711]
```

About 94% of three letter sequences have an answer, but only two
thirds of four letter sequences.
As we increase the number of letters, the odds for success are
increasingly dire.
But these numbers are still much higher than I expected.

#### Common words

The numbers are higher because the corpus
includes ridiculous words like "spoffle" and "pewdom".
To get a more realistic measure, we can replace `words` with
the most common words occurring in a corpus of real text.
An oldie but a goodie is the `brown` corpus, created at Brown
University in 1961.
I'm going to use it mainly because it's relatively small.

First, we make a list of all the words (with repetition) in the
corpus, then obtain a frequency distribution using the `nltk` function
`FreqDist`.
We then list the frequencies themselves, and truncate to most common
20,000 words.
Note that, in order to avoid getting swamped by "plumbing" words like
"the", we take them out using the `stopwords` corpus:

```python
nltk.download('brown')
nltk.download('stopwords')
from nltk.corpus import brown, stopwords

fdist = nltk.FreqDist(word.lower() for word in brown.words()
	if word not in stopwords.words('english'))
freqs = [fdist[word] for word in list(fdist.keys())]
freqs.sort(reverse = True)
cutoff = freqs[20000]
common = [word for word in list(fdist.keys())
	if fdist[word] >= cutoff] + stopwords.words('english')
```

This can obviously be modified for an arbitrary corpus and frequency cutoff.
Our list `common` gives us a list of the most 20,000 common
non-stopwords in the `brown` corpus, plus `stopwords`.
We then simply replace `words.words()` with `common`.
I won't provide the code here, just the chances of success:

```python
>>> [commprop(2), commprop(3), commprop(4), commprop(5), commprop(6)]
[0.9822, 0.7606, 0.3264, 0.0635, 0.0056]
```

This is closer to what I expect. Your chance of getting a four letter
combo (eventually) is only one in three, while your chance of getting
three letters is three in four.
And for five letters, forget about it!

#### Sublet variants for more letters

Given the basic statistical difficulty of playing the game with four
letters, one might ask for variants that are easier.
A simple option is allowing for rearrangment of letters, but
penalising the number of swaps.
For instance, "mqua" can be rearranged to "aqum" via a single swap,
and is a subsequence of "aquamarine".
One could also discard letters, e.g. "mqua" becomes "qua", with
supersequence "quantum".
I'm not sure exactly how scoring would work, since the simplicity of
sublet is that success on a round is clearly defined, and I don't know
what the chances of success are.
I'll leave both problems for another rainy day blog post!

<!-- http://www.nltk.org/book/ch02.html -->
<!-- https://stackoverflow.com/questions/28392860/print-10-most-frequently-occurring-words-of-a-text-that-including-and-excluding -->
