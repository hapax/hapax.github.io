---
Layout: post
mathjax: true
comments: true
title:  "Language, cognition and alien math (Part I)"
categories: [Philosophy]
date:  2020-07-08
---

**July 13, 2020.** *Linguistic relativism is the notion that language
  determines reality. Here, I introduce a variant called cognitive
  relativism, and interrogate the inner life of a bat, a brick, and a
  flock of birds. This will prepare us (hopefully) to think about
  alien mathematics!*

<!-- Alien algebra, bat brains and other cognitive conundra -->

#### Linguistic relativism in brief

<span style="padding-left: 20px; display:block">
We cut nature up, organize it into
concepts, and ascribe significances as we do, largely because we are
parties to an agreement to organize it in this way—an agreement that
holds throughout our speech community and is codified in the patterns
of our language.
</span>

<!-- We dissect nature along lines laid down by our native language. The
categories and types that we isolate from the world of phenomena we do
not find there because they stare every observer in the face; on the
contrary, the world is presented in a kaleidoscope flux of impressions
which has to be organized by our minds—and this means largely by the
linguistic systems of our minds. -->

<div style="text-align: right"><i>Benjamin Whorf</i> </div>

<span style="padding-left: 20px; display:block">
If a lion could talk, we could not understand him.
</span>

<div style="text-align: right"><i>Ludwig Wittgenstein</i> </div>

Language, it seems, is tied to our view of reality.
Two famous and contested examples: the Inuit have
[more root words for snow](https://en.wikipedia.org/wiki/Eskimo_words_for_snow)
than English, while the
[Hopi language reflects a different conception of time](https://en.wikipedia.org/wiki/Hopi_time_controversy).
(The former seems more attested than the latter.)
The claim that language affects our perception of reality is called
*linguistic relativism*. "Strong" linguistic
relativism states that your languages *determines* your reality.
"Weak" relativism claims that language merely
influences your reality.
Perception is downstream either way.

Perhaps the sharpest version of the hypothesis is that
[colour words](https://en.wikipedia.org/wiki/Linguistic_relativity_and_the_color_naming_debate)
reflects cultural differences in the perception of colour.
This ties into a 19th century prediliction for making cognitive
judgments on the basis of style.
For instance, the rarity of colour words in the epics of Homer led
British politician William Gladstone to write that

<span style="padding-left: 20px; display:block">
...the organ of color and its impressions were but partially
developed among the Greeks of the heroic age.
</span>

Pomposity aside, there is a scientific thesis
here.
In fact, experiments by cognitive linguists suggest that colour
terminology *does* lead to small differences of performance in
tasks involving memorisation and categorisation of colour.
Colour terminology is correlated with something.
But rather than proving relativism, I think the best way to understand
these experiments is to relinquish the false dichotomy between
relativism and universalism altogether.

#### Language, culture and cognition

<!-- The controversy seems amusingly overblown. -->
Would anyone really be surprised to learn that there are more words
for snow in Inuktitut than Amharic?
This seems about as shocking as the existence of the periodic table.
I would expect Inuit hunters to outperform their Ethiopian
counterparts in tasks involving fine-grained perceptions of snow,
since their survival literally depends on it.
<!--Like chemists, there should be measurable cognitive differences as a
result of training, and learning the lingo is part of that training.
<!-- since, like a chemist, they are trained to do so.
Put differently, survival *depends* on measurable cognitive
differences that are plausibly reflected in the language. -->
<!-- There is every reason to suppose there are measurable cognitive
differences; survival depends on it. -->
Similarly, the periodic table does not embody a mere
"agreement that holds throughout the speech community";
<!-- Certainly it is an agreement, but it not an arbitrary one.-->
rather, it encodes facts about the world chemists care to pay attention to.
I use the word "encode" deliberately, since words *tokenise relevant
differences* in a way that aids compression.
It takes less bytes to say things, and lowers the cognitive
burden of storage and manipulation, so both reasoning and
communication are easier.

But reference is only one aspect of language.
<!-- Our brain, with its phylogenetic onion skin of drives of abilities, is
 fantastically elaborated in human culture. -->
Our uniquely human drives and needs are expressed in *culture*.
Culture, in turn, is woven marvellously through with its language
games of family, hierarchy, art, courtship, religion, custom,
protocol, and so forth.
<!-- It will also presumably have cultural relevance, with words playing an
important role in the system of concepts, hierarchies, relationships and language
games that human culture is built on.
Tokenises relevant differences is facilitates reasoning and -->
<!-- communication. -->
Language and culture are not synonymous, as founding relativist
Edward Sapir points out:

<span style="padding-left: 20px; display:block">
It is easy to show that language and culture are not intrinsically
associated. Totally unrelated languages share in one culture; closely
related languages—even a single language—belong to distinct culture
spheres.
</span>

But show me a culture without register, slang, or other forms of
sociolinguistic variance and local colour, and I will show you a sloppy lexicologist.

Culture and language partially adapt and create each other,
co-evolving to serve
<!-- slang, patois,  and other vernacular adaptations -->
<!-- All this suggests that language organically co-evolves with -->
<!-- of life in a particular time and place. -->
cognitive and social demands.
If we split these forces up and decide on some fixed order of
influence, the cart will be before the horse, whichever order we
choose.
<!-- They are oceanic rather than riverine.
<!--Linguistic relativism is wrong, not because language does not affect
thought, but rather, because they organically co-evolve.-->
Linguistic universalism, relativism's opposite number, seems to me to
make the same error of unidirectional generalisation.
A mnemonic, for instance, is a way of shaping cognition with language, and education
is (in part) the mnemonic of a whole structure of life, a process of
enculturation and cognitive bootstrapping via the written and spoken word.
Clearly, language can influence perception and thought.
<!--(Of course, teaching has a strongly social aspect as well, but the -->
<!--point is that the influence is sometimes relatively unilateral, -->
<!--pace universalism.)-->

#### Cognitive universalism and relativism

But that influence can't happen in just any old way.
Brains are brains, obeying the [Hebbian](https://en.wikipedia.org/wiki/Hebbian_theory)
maxim that "neurons that fire together, wire together".
If linguistic relativism is a claim that language changes our brains
in any way *other than* Hebbian learning (or a related,
neuronally-grounded learning mechanism), then it is probably wrong.
Similarly, if universalism claims that language *cannot* change our
brains in a Hebbian fashion, it is wrong.
And what is Hebbianly possible is a question for neuroscientists
rather than linguists.
The only way for perception to be fundamentally different---rather
than the result of Hebbian training---is for brains to magically change as we
cross the boundaries of culture, race or speech community.
*Cognitive universalism* is the empirically defensible claim this
does not happen.
Different people have different brains, certainly, but the variation
between individuals is greater than the variation between cultures.
Brains in Peru form some plane of cognitive variance; a brain in
Spain falls mainly on this plane.
<!-- brain in spain falls mainly on the plane -->
<!-- While the version of linguistic universalism just outlined is -->
<!-- wrong, *cognitive universalism* (closer to what most universalists believe)
is more defensible. -->

Language and culture clearly have effects on how we operate.
In fact, they can be viewed as "operating systems" <!-- *interfaces*-->
interfacing between the IO of reality (including the reality of our
fellow featherless bipeds) and our relatively invariant
cognitive hardware.
These operating systems differ not only because reality varies (sub-Saharan Africa is not
Nunangat), but because the choice of interface is radically
non-unique.
<!-- Interfaces differ, since reality differs (sub-Saharan Africa is not
Nunangat), and even for the same local conditions, the choice of -->
<!-- interface is radically non-unique. -->

If cognitive universalism within the species is a biological fact,
between species we would expect a form of *cognitive relativism* to hold.
A dog snuffling around in the undergrowth, a bat navigating by
sonar, and a human piloting an F-15, are experiencing the world
in different ways; each "sees" things the other cannot, and is
afforded new possibilities for action as a result.
As with language, we can distinguish two forms of
cognitive relativism.
The strong form states that your brain (or cognitive architecture)
determines your reality, with the upshot that different animals will
have *incommensurable* experiences.
(This is like the claim that some things
are untranslatable.)
The weak version replaces "determines" with "influences".

I think the weak version is uncontroversially true, so for the rest of this
post, we will focus on the strong form, and incommensurability in
particular.
An immediate objection is that a gnat is simply not neurally equipped to
understand human experience, so of course our experience is
incommensurable to it.
But what about the other way round?
Can we "simulate" life as a gnat, which is evidently much lower on the
cognitive ladder?
More generally, can *any creature simulate any other creature*?
This leads to a sharp version of strong cognitive relativism: two
organisms will have incommensurable experiences unless they have the
same sort of brain.

#### The inner life of bats

The most famous argument for incommensurability is Thomas Nagel's
[*What is it like to be a bat?*](http://www.philosopher.eu/others-writings/nagel-what-is-it-like-to-be-a-bat/).
Nagel is really interested in showing there is an *interior* aspect
to consciousness that cannot be captured by reductive explanation;
in a slogan, mind is different from brain. But his argument relies on
incommensurability
<!-- of human and chiropteran experience, that there is-->
to suggest there is
"something it is like" to be a bat which humans cannot simulate.
This "something" is mind. 
As he puts it:

<span style="padding-left: 20px; display:block">
Even without the benefit of philosophical reflection, anyone who has
spent some time in an enclosed space with an excited bat knows what it
is to encounter a fundamentally alien form of life... [B]at sonar,
though clearly a form of perception, is not similar in its operation
to any sense that we possess, and there is no reason to suppose that
it is subjectively like anything we can experience or imagine.
This appears to create difficulties for the notion of what it is like to be a bat.
</span>

There is no real argument here (or the rest of the paper for that
matter), just the bald assertion that echolocation "appears to create
difficulties" for getting inside a bat's head.
Can we do better?

<!-- Nagel's account of the phenomenology feels more plausible than
his anti-reductionism, but we'll leave a critical evaluation for
another time. -->

The German biologist Jakob von Uexküll
<!-- approached the inner life of
animals a little more systematically. -->
provides one such approach.
Uexküll wanted to understand how organisms model and interact with their
environments, and thereby create meaning.
He used the term [*umwelt*](https://en.wikipedia.org/wiki/Umwelt) (German for "environment") for athe synthesis of factors

<span style="padding-left: 20px; display:block">
...constituted by a more or less broad series of elements, 'carriers of
significance' or 'marks' which are the only things that interest the
animal.
</span>

I think this is an instructive philosophy.
By carefully considering the "marks" available to the bat, learning
about cave topography, feeding habits, social structure,
experimenting with human echolocation, and so on---in other words, becoming
practical ethologists---the
imaginative obstructions do not seem fundamental.
<!-- Nagel's claims becomes less intuitive, since -->
This closely parallels Daniel Dennett's notion of
"heterophenomenology" in
[his reply to Nagel](https://ase.tufts.edu/cogstud/dennett/papers/what_is_it_like_to_be_a_bat.pdf),
so we will adopt this term for ethologists who try to experience the inner life of other animals.
Although there is no conceivable sequence of Hebbian changes that will
turn me into a bat, with enough effort I could maybe simulate one.

#### Functional gestalts and the heterophenomenological arcade

<!-- But while there may or may not be something it is like to be a
bat, -->
A bat,
unlike a human, knows how to operate all of its interlocking cognitive
machinery seamlessly and in real time.
The different components form a "functional gestalt", defined
precisely by all the parts operating together at once; in fact, it
seems reasonable to identify this gestalt with the *umwelt* itself.
There is no magic or phenomenology here, just an organism competent at
living.
And the competent organism
["knows how"](https://plato.stanford.edu/entries/knowledge-how/) while
the ethologist "knows that".
You might be the world's greatest expert on bat heterophenomenology,
but to learn *how* to drive the batmobile, you probably need to spend
some time in the driver's seat.
<!-- It's unclear just how an ethologist *could* come to "know
that" without literally being embedded in the bat brain.
<!-- This is just the old distinction between
["knowing how" and "knowing that"](https://plato.stanford.edu/entries/knowledge-how/),
but applied to brains interfacing with reality. 
We can know all the marks, and how they fit together, but this does
not allow us to simulate the *fitting together* itself, since this
likely requires. -->

<!-- Thus, true heterophenomenology, knowing "what it is like" to be a bat,
would not only consist in researching the bat's exotic sensory
modalities, available environmental marks, and so on. -->
To get driving practice, you would have to be *immersed* in a bat-like
environment and obliged to use bat-like interfaces
to solve bat-like problems, for a suitably long period of time.
I think "bat-like" is good enough to reproduce the *functional* aspect
of this gestalt; to adopt the functionalist motto, we simply want to
reproduce the relationships between outputs and inputs, and
analogues will do if they mirror these relationships.
Thus, we are led to imagine a "heterophenomenological arcade",
offering a full range of non-human inner lives, consisting of full-body VR
immersion tanks with haptic, olfactory and other sensory
feedback loops.

It would be even more stringent if these arcade units were wired up to
real animals, e.g. the bat tank translated sensory inputs from a
real bat into human-readable form, and then translted the human
operator's decisions into bat action.
If the human could successfully drive the batmobile with enough
training, i.e. respond to the *umwelt* demands of the bat, I would say
that its experience was commensurable.
But if there is no way to produce human-readable functional analogues,
or train the human to successfully solve bat problems, then we have an
empirically grounded claim of cognitive incommensurability.
The heterophenomenological arcade is the testing ground for
strong cognitive relativism.

<!-- If immersion is a recipe for producing *fluency* in being a
bat, it is not by coincidence the main way humans become fluent in
other languages and cultures.
Speaking from personal experience, merely trying to learn the
components of a language, without
functionally uniting them, makes fluency very difficult to achieve.
<!--, I suspect for the same functionalist reasons. -->
<!-- But immersion may not always be possible.
For instance, the sensory modalities might just be too weird, or the
different parts too unwieldy for our brains to weld into a functional
whole.
I would say that in this case, we have an empirically grounded claim
of cognitive incommensurability.
I think strong cognitive relativism is a testable hypothesis, which we
need a heterophenomenological arcade to test. -->

#### Hive minds, consciousness and bricks

We finish with a couple of miscellaneous observations.
First, there is no reason for this functional gestalt to be confined to
individual organisms. There is a functional gestalt, a "how", to being
part of a telepathically linked hive mind, something more amorphously
collective like a slime mould, a planetary consciousness, and so on.
<!-- (We will return to this point in the sequel.)-->
So in general, the mysterious "interiority" Nagel talks about need not be associated
with an individual, but simply *any* functional gestalt that requires
executive coordination.
<!-- , and indeed, I was briefly tempted 
to view this executive gestalt operation as consciousness itself.
<!-- ut this very easily traps
us in the bad regress of homonculi and Cartesian theatre. The point is
that "knowing how" to competently wield a brain is a central
component of the organism's cognitive machinery and can be understood
in functional terms.
<!-- One curious observation: there is a functional gestalt associated with
being a brick, or perhaps more 
I am not advocating panpsychism, since there is no "knowing how"
with a brick. It does not need to be a competent operator, it simply exists
according to the laws of physics. -->
<!-- Nor do I want to
[Quine qualia](https://ase.tufts.edu/cogstud/dennett/papers/quinqual.htm).
I think there is still a phenomenological aspect to explain, even if
it is to heroically explain away. My goal is get more traction on
incommensurability than afforded by the sweaty palms of a Nagelian -->
<!-- mystic. -->
<!-- But on reflection, it's clear that even from a functionalist view,
merely invoking a gestalt is not enough to explain the special
properties of what it is like to have experience. -->

Secondly, while functional gestalts seem like a good way to test
incommensurability, they are most likely distinct from the
phenomenological aspects of mind Nagel posits.
*Anything* made up of interlocking capacities and abilities has a
functional gestalt, a fluency of action when those capacities and
abilities are successfully operated in tandem.
<!-- (In fact, one can associate a gestalt to unrelated functions, but we
will not need to enlist this reductio.) -->
By this liberal definition, there is a functional gestalt
associated with being a flock of birds or perhaps even a brick.
A flock of birds also has an *umwelt*, a set of marks that are
available and of interest *to the flock as a whole*.
Ethologists do study these sorts of *umwelten* under the umbrella of
collective animal behaviour,
<!-- Bird flocks can certainly be understood in terms of "collective
ethology". -->
but going even further, one can imagine a murmuration tank in the
heterophenomenological arcade, simulating the *umwelt* of a flight of starlings.

<!-- One can imagine designing a game which immerses humans in the
experience of "being" a flock of birds, responding to those marks, and
so on. -->

But while the human may have some inner experience of "what is it
like" to be a flock of birds, it is highly unlikely that the flock
itself has that experience.
This is simply because the human has some ability over and above the
flock, namely, a feedback loop on the contents of experience which has
those qualitative aspects that cause the philosophers so much befuddlement.
In functional terms, this feedback loop seems very different from
whatever system of cues allows the birds to flock coherently.
<!-- On the other hand, I think that with enough training, a human
might be able to simulate this system of cues using the feedback loop. Even in functional terms, it is clearly different from executive
coordination. 
This is part of what might allow them to simulate the executive
coordination of the flock, but it is rather different from whatever
cues the birds exchange in order to flock coherently. -->
It is amusing to note that, in a sort of relativist double entendre,
the "language" of cues might in some sense determine the cognition of
the flock!
<!-- (It's tempting to make the same high-flown leap for the collective
behaviour of humans, but ultimately, I think human culture is more
tied up in human drives and needs than it is in language.) -->

Above, we suggested that from a functionalist perspective, near enough
is good enough.
We need not surgically implant bat ears if we can "mock up" a
functionally equivalent form of echolocation.
But if consciousness has a functional characterization, it raises a strange
question: is it possible to mock up a "near enough is good enough"
functional analogue for a creature which does not have conscious experience?
Naturally, such a creature would need to have enough cognitive
machinery to *simulate* consciousness, and one might ask how this
could be possible if it was not self-aware to begin with.
I will explore some possibilities in Part II, but if such an analogue
exists, even in principle, it would answer Daniel Dennett's mocking
rejoinder to Nagel, "What is it like for there to be something it is
like to be something?"
<!-- (This clearly has functional aspects, but it is the qualitative aspects
that trouble philosophers.) -->
<!-- An even sillier example than the flock of birds is the brick, which I
leave as homework to the diligent heterophenomologist. -->
In the mean time, I leave the heterophenomenology of bricks as
homework for the diligent reader.

<!-- More dramatic and amusing, there is a gestalt associated to *any*
unrelated collection of functions, defined precisely by being
unrelated to the extent that they are!
Is there anything it is like to be  -->

#### Next time: alien mathematics

So finishes Part I.
Next time, we'll consider convergent evolution, aliens, and
how reality itself might ground interspecific discourse in
the same way that cognitive universalism grounds intraspecific
discourse.
In particular, we'll consider the claim that mathematics acts as a
"universal language" and some radically different forms that alien
mathematics might take.

<!-- In computational terms, the *umwelt* is an effort to reverse engineer
the operating system from the IO.
There is a tacit functionalist assumption here that *IO determines OS*.
But there is more than one way to skin a bat!
Solutions to biological problems are non-unique, as human culture
shows; operating systems are underconstrained by what you do with
them. 
Nagel would argue that even if we rationally understand the
*umwelt*, that does not render the experience commensurable.
There is an internal aspect our model cannot capture.

I suspect the truth is somewhere in between.
If we could understand all the relevant carriers of meaning, but more
subtly, the *ways they are encoded and manipulated by the interface*,
I think we would be a good deal closer to understanding what it is
like to be a bat.
These are in principle discoverable by neuroscience, but not zoology.
That said, there is probably a gestalt aspect to *operating the
interface* which understanding all its parts does not give.
This is, roughly speaking, the distinction between
["knowing how" and "knowing that"](https://plato.stanford.edu/entries/knowledge-how/).
And at a cognitive level, there is no conceivable sequence of Hebbian changes
that will turn me into a bat. -->

<!-- #### Alien brain, alien mind?

Incommensurability has implications for extraterrestrial life.
From the
[Voyager record](https://en.wikipedia.org/wiki/Voyager_Golden_Record)
to [SETI@home](https://setiathome.berkeley.edu/), efforts to talk to
aliens represent experiments in cognitive relativism.
The question they pose is: could  develop convergently?

[Convergent evolution](https://en.wikipedia.org/wiki/Convergent_evolution)
occurs when phylogenetically distant organisms converge on similar
solutions to similar problems.
The most famous example is the eye, where vertebrates and cephalopods
evolved the same biological camera from the single photoreceptive
pixel of their most recent common ancestor.

<!-- Despite all this talk of generic non-uniqueness, I think that
commensurability is probably an empirical question.
If so, the simplest way to phrase cognitive relativism is that
mind [supervenes](https://plato.stanford.edu/entries/supervenience/) on the
brain: no experiential difference without a brain difference, though
the converse need not hold.
Supervenience of mind on brain is weaker than strict identification,
and gives ontological wiggle room for Nagelian phenomenology (if one
is so inclined), while allowing for the possibility that the same sort
of mind could arise from different sorts of brain.
Similar minds would be commensurable. -->

<!-- There are biological precedents for this idea.
[Convergent evolution](https://en.wikipedia.org/wiki/Convergent_evolution)
occurs when phylogenetically distant organisms converge on similar
solutions to similar problems.
The most famous example is the eye, where vertebrates and cephalopods
evolved the same biological camera from the single photoreceptive
pixel of their most recent common ancestor.
Could mind also develop convergently?
Though it sounds like a dusty quibble, this question is
central to our search for extraterrestrial life!
From the
[Voyager record](https://en.wikipedia.org/wiki/Voyager_Golden_Record)
to [SETI@home](https://setiathome.berkeley.edu/), efforts to talk to
aliens represent experiements in cognitive relativism. 

When *umwelten* overlap, Estonian semoiotician Yuri Lotman proposed
that a ["semiosphere"](https://en.wikipedia.org/wiki/Semiosphere)
results: a realm of shared meaning that arises by virtue of shared
"marks".
For instance, I think humans enjoy the company of dogs, and vice
versa, due to a generous overlap of *umwelten*.
Many of their pleasures are our pleasures (though by no means all,
as frolicking in carrion shows).
To establish meaningful connection with an alien mind, the semiosphere
cannot be empty.

The possibilities for radical differences in alien culture and biology
are part of an
[established set of tropes](https://tvtropes.org/pmwiki/pmwiki.php/Main/AlienTropes).
But in the same way that an intraspecific universalist can fall back
on the bedrock of conition to ground translation and intercultural
dialogue, science fiction often falls back on the bedrock of reality
to ground interspecific dialogue.
We may find the tentacles offputting and the customs bizarre, but we
can always talk about gravity and prime numbers instead. -->

<!-- Sometimes, intelligence is lumped into the same category as the eye. But while the camera eye can be described in a sentence---light
passses through a pinhole onto a photoreceptive screen---there is no
simple definition of intelligence current among biologists. --> 

<!-- Let's leave the problem
The natural yardstick for incommensurability is phylogenetic.
The further away you look on the Tree of Life, the greater the
imaginative obstructions, the more exotic the sensory modalities and
carriers of meaning, the more radically different the *umwelten*.
A bat is not "fundamentally alien".
It is a mammal, so we share large chunks of brain function and DNA.
But what if we were to encounter beings from a different Tree altogether?
I would place a very high prior on incommensurability of some sort. -->

<!-- http://www.hutter1.net/ai/uaibook.htm -->

<!-- And it seems like the incomparability between these strange -->
<!-- organisms would be pairwise mutual. An anglerfish and a bat have -->
<!-- about as much in common as a bat and an anglerfish and a human. But there is a whole class -->
<!-- The more pronounced the imaginative obstructions, the more plausible
strong cognitive relativism seems.
But when we look nearby on the Tree of Life, it becomes less so.
I doubt I can simulate an anglerfish, but what about a chimpanzee?
There are no exotic sensory modalities a Nagelian could use as proof
of incommensurability. In fact, their brain is almost identical to
ours. -->
<!-- A human child raised by chimpanzees would probably have the same
gestalt experience as a chimpanzee, and the imaginative obstructions
to human adults are more likely neuroplastic than fundamentally
cognitive. -->
<!-- This is *consistent* with strong cognitive relativism, 
finessed to take cognitive similarity into account.
Similar brains lead to similar realities, so incommensurability itself
is a relative affair.
But there -->
