---
Layout: post
mathjax: true
comments: true
title:  "Cognitive relativism and mathematics"
categories: [Mathematics, Philosophy]
date:  2020-07-08
---

**July 13, 2020.** *Bla*

#### Linguistic relativism in brief

<span style="padding-left: 20px; display:block">
We cut nature up, organize it into
concepts, and ascribe significances as we do, largely because we are
parties to an agreement to organize it in this way—an agreement that
holds throughout our speech community and is codified in the patterns
of our language.
</span>

<!-- We dissect nature along lines laid down by our native language. The
categories and types that we isolate from the world of phenomena we do
not find there because they stare every observer in the face; on the
contrary, the world is presented in a kaleidoscope flux of impressions
which has to be organized by our minds—and this means largely by the
linguistic systems of our minds. -->

<div style="text-align: right"><i>Benjamin Whorf</i> </div>

Language, it seems, is naturally tied to our view of reality.
Two infamous examples: according to some linguists, the Inuit have
[more root words for snow](https://en.wikipedia.org/wiki/Eskimo_words_for_snow)
than English, while the
[Hopi language reflects a different conception of time](https://en.wikipedia.org/wiki/Hopi_time_controversy).
The claim that language affects our perception of reality is called
*linguistic relativism*. "Strong" linguistic
relativism states that your languages *determines* your reality.
"Weak" relativism makes the weaker claim that language merely
influences your reality; perception is somehow downstream from
language.

Perhaps the sharpest version of the hypothesis is that
[colour words](https://en.wikipedia.org/wiki/Linguistic_relativity_and_the_color_naming_debate)
reflects cultural differences in the perception of colour.
This ties into a 19th century prediliction for making cognitive
judgments on the basis of style.
For instance, the rarity of colour words in the epics of Homer led
British politician William Gladstone to write that

<span style="padding-left: 20px; display:block">
...the organ of color and its impressions were but partially
developed among the Greeks of the heroic age.
</span>

Pomposity aside, there is a scientific thesis
here.
In fact, experiments by cognitive linguists suggest that colour
terminology *does* lead to differential performance in tasks which involve
remembering and categorising colours.
In other words, colour terminology does seem to be tied to
measurable differences in perception.
But rather than proving relativism, I think the best way to understand
these experiments is to relinquish the false dichotomy between
relativism and universalism altogether.

#### Language, culture and cognition

<!-- The controversy seems amusingly overblown. -->
Would anyone really be surprised to learn that there are more words
for snow in Inuktitut than Amharic?
This seems about as shocking as the existence of the periodic table.
I would expect Inuit hunters to outperform their Ethiopian
counterparts in tasks involving fine-grained perceptions of snow,
since their survival literally depends on it.
Like chemists, there should be measurable cognitive differences as a
result of training, and learning the lingo is part of that training.
<!-- since, like a chemist, they are trained to do so.
Put differently, survival *depends* on measurable cognitive
differences that are plausibly reflected in the language. -->
<!-- There is every reason to suppose there are measurable cognitive
differences; survival depends on it. -->
The periodic table does not embody a mere
"agreement that holds throughout the speech community";
<!-- Certainly it is an agreement, but it not an arbitrary one.-->
rather, it encodes facts about the world chemists care to pay attention to.
I use the word "encode" deliberately, since words *tokenise relevant
differences* in a way that aids compression.
It literally takes less bytes to say things, and lowers the cognitive
burden of storage and manipulation, so both reasoning and
communication are facilitated.

But reference is only one aspect of language.
<!-- Our brain, with its phylogenetic onion skin of drives of abilities, is
 fantastically elaborated in human culture. -->
Our uniquely human drives and needs are expressed in *culture*, woven
marvellously through with its language games of family, hierarchy,
courtship, religion, custom, protocol, and so forth.
<!-- It will also presumably have cultural relevance, with words playing an
important role in the system of concepts, hierarchies, relationships and language
games that human culture is built on.
Tokenises relevant differences is facilitates reasoning and -->
<!-- communication. -->
Language and culture are not synonymous, as founding relativist
Edward Sapir pointed out:

<span style="padding-left: 20px; display:block">
It is easy to show that language and culture are not intrinsically
associated. Totally unrelated languages share in one culture; closely
related languages—even a single language—belong to distinct culture
spheres.
</span>

But show me a culture without slang, register, and other forms of
vernacular adaptation and sociolinguistic variance, and I will show
you an incompetent lexicologist.

Culture and language partially adapt and create each other,
co-evolving to serve the
<!-- slang, patois,  and other vernacular adaptations -->
<!-- All this suggests that language organically co-evolves with -->
<!-- culture and the -->
cognitive demands of life in a particular time and place.
If we split these forces up and decide on some fixed order of
influence, the cart will be before the horse, whichever order we
choose!
Language and culture are oceanic rather than riverine.
<!--Linguistic relativism is wrong, not because language does not affect
thought, but rather, because they organically co-evolve.-->
Linguistic universalism, relativism's opposite number, seems to me to
make the same error of unidirectional generalisation.
A mnemonic, for instance, is a way of shaping cognition with language, and education
is (in part) the mnemonic of a whole structure of life, a process of
enculturation and cognitive bootstrapping via language.
Clearly, language can influence perception and thought.
<!--(Of course, teaching has a strongly social aspect as well, but the -->
<!--point is that the influence is sometimes relatively unilateral, -->
<!--pace universalism.)-->

#### Cognitive universalism and relativism

But that influence can't happen in just any old way.
Brains are brains, obeying the [Hebbian](https://en.wikipedia.org/wiki/Hebbian_theory)
maxim that "neurons that fire together, wire together".
If linguistic relativism is a claim that language changes our brains
in any way *other than* Hebbian learning (or a related learning
mechanism), then it is probably wrong.
Similarly, if universalism claims that language *cannot* change our
brains in a Hebbian fashion, it is wrong.
And what is Hebbianly possible is a question for neuroscientists
rather than linguists.

The only way for perception to be fundamentally different---rather
than the result of Hebbian training---is if brains magically change as we
cross cultural, racial or even personal boundaries.
*Cognitive universalism* is the empirically defensible claim this
does not happen.
<!-- While the version of linguistic universalism just outlined is -->
<!-- wrong, *cognitive universalism* (closer to what most universalists believe)
is more defensible. -->
Rather, language and culture can be viewed as operating systems <!-- *interfaces*-->
interfacing between the IO of reality and our relatively invariant
cognitive hardware.
These operating systems differ not only because reality varies (sub-Saharan Africa is not
Nunangat), but because the choice of interface is radically
non-unique.
<!-- Interfaces differ, since reality differs (sub-Saharan Africa is not
Nunangat), and even for the same local conditions, the choice of -->
<!-- interface is radically non-unique. -->

If cognitive universalism within the species is a biological fact,
between species, we expect a form of *cognitive relativism* to hold
for similar reasons.
A dog snuffling around in the undergrowth, a bat navigating by
sonar, and a human piloting a jet engine, are experiencing the world
in different ways; each "sees" things the other cannot, and is
afforded new possibilities for action as a result.
As with language, we can distinguish two forms of
cognitive relativism.
The strong form states that your brain (or cognitive architecture)
determines your reality, with the upshot that brains which are too
different will have *incommensurable* experiences.
(This is like the claim made by lingustic relativists that some things
are untranslatable.)

#### The inner life of bats

The most famous argument for cognitive incommensurability is
Thomas Nagel's
[*What is it like to be a bat?*](http://www.philosopher.eu/others-writings/nagel-what-is-it-like-to-be-a-bat/).
Nagel wants to show there is an *interior* aspect to consciousness
that cannot be captured by reductive explanation, i.e. mind is
different from brain. But his argument relies on the
incommensurability of human and chiropteran experience, that there is
"something it is like" to be a bat which humans cannot simulate.
This "something" is mind.
As he puts it:

<span style="padding-left: 20px; display:block">
Even without the benefit of philosophical reflection, anyone who has
spent some time in an enclosed space with an excited bat knows what it
is to encounter a fundamentally alien form of life... [B]at sonar,
though clearly a form of perception, is not similar in its operation
to any sense that we possess, and there is no reason to suppose that
it is subjectively like anything we can experience or imagine.
This appears to create difficulties for the notion of what it is like to be a bat.
</span>

Nagel's account of the phenomenology of bats feels more plausible than
his anti-reductionism, but we'll leave a critical evaluation for
another time.

A more systematic approach to conceptualising the inner life of other animals is the
[*umwelt*](https://en.wikipedia.org/wiki/Umwelt) model of biologist Jakob von Uexküll.
Uexküll wanted to understand how animals create meaning, model and
interact with their environments.
The *umwelt* (German for "environment") is a synthesis of these
factors,

<span style="padding-left: 20px; display:block">
...constituted by a more or less broad series of elements, 'carriers of
significance' or 'marks' which are the only things that interest the
animal.
</span>

In computational terms, the *umwelt* is an effort to reverse engineer
the operating system from the IO.
There is a tacit functionalist assumption here that *IO determines OS*.
But there is more than one way to skin a bat!
Solutions to biological problems are non-unique, as human culture
shows; operating systems are underconstrained by what you do with
them.

Further, Nagel would argue that even if we rationally understand the
operating system, that does not render the experience commensurable.
There is an internal aspect our model cannot capture.
I suspect the truth is somewhere in between.
If we could understand all the relevant carriers of meaning, but more
subtly, the *ways they are encoded and manipulated by the interface*,
I think we would be a good deal closer to understanding what it is
like to be a bat.
These are in principle discoverable by neuroscience, but not zoology.
That said, there is probably a gestalt aspect to *operating the
interface* which understanding all its parts does not give.
This is, roughly speaking, the distinction between
["knowing how" and "knowing that"](https://plato.stanford.edu/entries/knowledge-how/).
And at a cognitive level, there is no conceivable sequence of Hebbian changes
that will turn me into a bat.

#### Alien brain, alien mind?

Despite all this talk of generic non-uniqueness, I think that
commensurability is probably an empirical question.
If so, the simplest way to phrase cognitive relativism is that
mind [supervenes](https://plato.stanford.edu/entries/supervenience/) on the
brain: no experiential difference without a brain difference, though
the converse need not hold.
Supervenience of mind on brain is weaker than strict identification,
and gives ontological wiggle room for Nagelian phenomenology (if one
is so inclined), while allowing for the possibility that the same sort
of mind could arise from different sorts of brain.
Similar minds would be commensurable.

There are biological precedents for this idea.
[Convergent evolution](https://en.wikipedia.org/wiki/Convergent_evolution)
occurs when phylogenetically distant organisms converge on similar
solutions to similar problems.
The most famous example is the eye, where vertebrates and cephalopods
evolved the same biological camera from the single photoreceptive
pixel of their most recent common ancestor.
Could mind also develop convergently?
Though it sounds like a dusty quibble, this question is
central to our search for extraterrestrial life!
From the
[Voyager record](https://en.wikipedia.org/wiki/Voyager_Golden_Record)
to [SETI@home](https://setiathome.berkeley.edu/), efforts to talk to
aliens represent experiements in cognitive relativism.

When *umwelten* overlap, Estonian semoiotician Yuri Lotman proposed
that a ["semiosphere"](https://en.wikipedia.org/wiki/Semiosphere)
results: a realm of shared meaning that arises by virtue of caring
about the same environmental "marks".
I think humans enjoy the company of dogs, and vice versa, due to a
generous overlap of *umwelten*.
Many of their pleasures are our pleasures (though by no means all,
e.g. frolicking in carrion).
To establish meaningful connection with an alien mind, the semiosphere
cannot be empty.

<!-- Sometimes, intelligence is lumped into the same category as the eye. But while the camera eye can be described in a sentence---light
passses through a pinhole onto a photoreceptive screen---there is no
simple definition of intelligence current among biologists. --> 

<!-- Let's leave the problem
The natural yardstick for incommensurability is phylogenetic.
The further away you look on the Tree of Life, the greater the
imaginative obstructions, the more exotic the sensory modalities and
carriers of meaning, the more radically different the *umwelten*.
A bat is not "fundamentally alien".
It is a mammal, so we share large chunks of brain function and DNA.
But what if we were to encounter beings from a different Tree altogether?
I would place a very high prior on incommensurability of some sort. -->

<!-- http://www.hutter1.net/ai/uaibook.htm -->

<!-- And it seems like the incomparability between these strange -->
<!-- organisms would be pairwise mutual. An anglerfish and a bat have -->
<!-- about as much in common as a bat and an anglerfish and a human. But there is a whole class -->
<!-- The more pronounced the imaginative obstructions, the more plausible
strong cognitive relativism seems.
But when we look nearby on the Tree of Life, it becomes less so.
I doubt I can simulate an anglerfish, but what about a chimpanzee?
There are no exotic sensory modalities a Nagelian could use as proof
of incommensurability. In fact, their brain is almost identical to
ours. -->
<!-- A human child raised by chimpanzees would probably have the same
gestalt experience as a chimpanzee, and the imaginative obstructions
to human adults are more likely neuroplastic than fundamentally
cognitive. -->
<!-- This is *consistent* with strong cognitive relativism, 
finessed to take cognitive similarity into account.
Similar brains lead to similar realities, so incommensurability itself
is a relative affair.
But there -->
