<!-- If immersion is a recipe for producing *fluency* in being a
bat, it is not by coincidence the main way humans become fluent in
other languages and cultures.
Speaking from personal experience, merely trying to learn the
components of a language, without
functionally uniting them, makes fluency very difficult to achieve.
<!--, I suspect for the same functionalist reasons. -->
<!-- But immersion may not always be possible.
For instance, the sensory modalities might just be too weird, or the
different parts too unwieldy for our brains to weld into a functional
whole.
I would say that in this case, we have an empirically grounded claim
of cognitive incommensurability.
I think strong cognitive relativism is a testable hypothesis, which we
need a heterophenomenological arcade to test. -->

#### Hive minds, consciousness and bricks

I finish with a couple of miscellaneous observations.
First, there is no reason for this functional gestalt to be confined to
individual organisms. There is a gestalt, a "how", to being
part of a telepathically linked hive mind, something more amorphously
collective like a slime mould, a planetary consciousness, and so on.
<!-- (We will return to this point in the sequel.)-->
<!-- So in general, the inner life Nagel talks about need not be associated
with an individual, but simply *any* functional gestalt that requires
executive coordination.
<!-- , and indeed, I was briefly tempted 
to view this executive gestalt operation as consciousness itself.
<!-- ut this very easily traps
us in the bad regress of homonculi and Cartesian theatre. The point is
that "knowing how" to competently wield a brain is a central
component of the organism's cognitive machinery and can be understood
in functional terms.
<!-- One curious observation: there is a functional gestalt associated with
being a brick, or perhaps more 
I am not advocating panpsychism, since there is no "knowing how"
with a brick. It does not need to be a competent operator, it simply exists
according to the laws of physics. -->
<!-- Nor do I want to
[Quine qualia](https://ase.tufts.edu/cogstud/dennett/papers/quinqual.htm).
I think there is still a phenomenological aspect to explain, even if
it is to heroically explain away. My goal is get more traction on
incommensurability than afforded by the sweaty palms of a Nagelian -->
<!-- mystic. -->
<!-- But on reflection, it's clear that even from a functionalist view,
merely invoking a gestalt is not enough to explain the special
properties of what it is like to have experience. -->

But not every functional gestalt has an "interior"
aspect.
There is a functional gestalt associated with being a flock of birds
or perhaps even a brick, but neither of these is likely to have any
true inner experience, for the simple reason that inner experience is
something over and above the ability to successfully operate many
abilities in tandem. It is a *feedback loop* on the
contents of its internal representations, as described in Byzantine
detail by people like Dennett and [Douglas Hofstadter](https://en.wikipedia.org/wiki/I_Am_a_Strange_Loop).

Whether or not it is *only* a functional phenomenon, the feedback loop
of conscious experience has clear functional implications for the organism, since it can
report on its internal contents.
A human operator might enter the murmuration tank in the
heterophenomenological arcade, successfully wield a flight of
starlings, and emerge with some "inner experience" of being that flock
that the flock does not have!
(Even sillier is the brick simulator.)
A flight of starlings does not need to be conscious to accomplish
its executive coordination, and attend to its collective *umwelt*.
Instead, the starlings presumably exchange a set of cues.
In a sort of relativist double entendre,
the "language" of these cues might in some sense determine the cognition of
the flock!

<!-- Secondly, while functional gestalts seem like a good way to test
incommensurability, they are most likely distinct from the
phenomenological aspects of mind Nagel posits.
*Anything* made up of interlocking capacities and abilities has a
functional gestalt, a fluency of action when those capacities and
abilities are successfully operated in tandem.
<!-- (In fact, one can associate a gestalt to unrelated functions, but we
will not need to enlist this reductio.) -->
<!-- By this liberal definition, there is a functional gestalt
associated with being a flock of birds or perhaps even a brick.
A flock of birds naturally has an *umwelt*, a set of marks that are
available and of interest to the flock as a whole, and ethologists
study these *umwelten* under the umbrella of collective animal behaviour,
<!-- Bird flocks can certainly be understood in terms of "collective
ethology". 
But going even further, one can imagine a murmuration tank in the
heterophenomenological arcade, simulating the *umwelt* of a flight of starlings. -->

<!-- One can imagine designing a game which immerses humans in the
experience of "being" a flock of birds, responding to those marks, and
so on. -->

<!-- But while the human may have some inner experience of "what is it
like" to be a flock of birds, it is highly unlikely that the flock
itself has that experience!
This is simply because the human has some ability over and above the
flock, namely, a feedback loop on the contents of experience with some
puzzling qualitative aspects.
<!-- which has those qualitative aspects that cause the philosophers so much befuddlement.
In functional terms, this feedback loop seems very different from
whatever system of cues allows the birds to flock coherently. -->
<!-- On the other hand, I think that with enough training, a human
might be able to simulate this system of cues using the feedback loop. Even in functional terms, it is clearly different from executive
coordination. 
This is part of what might allow them to simulate the executive
coordination of the flock, but it is rather different from whatever
cues the birds exchange in order to flock coherently. -->
<!-- It is amusing to note that, in a sort of relativist double entendre,
the "language" of cues might in some sense determine the cognition of
the flock!
<!-- (It's tempting to make the same high-flown leap for the collective
behaviour of humans, but ultimately, I think human culture is more
tied up in human drives and needs than it is in language.) -->

Finally, we suggested above that from a functionalist perspective,
near enough is good enough.
We need not surgically implant bat ears if we can "mock up" a
functionally equivalent form of echolocation.
But if consciousness has a functional characterization, it raises a strange
question: is it possible to mock up a "near enough is good enough"
functional analogue of consciousness for a creature which does not
possess it?
This is, of course, the "old" problem of AI: get a computer to
succeed at the conscious experience simulator.
<!-- Naturally, such a creature would need to have enough cognitive
machinery to *simulate* consciousness, and one might ask how this
could be possible if it was not self-aware to begin with. -->
<!-- It seems hard to imagine, but if such an analogue
exists, even in principle, I think it-->
And designing such a simulator would answer Daniel Dennett's mocking
rejoinder to Nagel: "What is it like for there to be something it is like to be something?"
<!-- (This clearly has functional aspects, but it is the qualitative aspects
that trouble philosophers.) -->
<!-- An even sillier example than the flock of birds is the brick, which I
leave as homework to the diligent heterophenomologist. -->

<!-- In the mean time, I leave the heterophenomenology of bricks as
homework for the diligent reader. -->

<!-- More dramatic and amusing, there is a gestalt associated to *any*
unrelated collection of functions, defined precisely by being
unrelated to the extent that they are!
Is there anything it is like to be  -->

# Next time


<!-- In computational terms, the *umwelt* is an effort to reverse engineer
the operating system from the IO.
There is a tacit functionalist assumption here that *IO determines OS*.
But there is more than one way to skin a bat!
Solutions to biological problems are non-unique, as human culture
shows; operating systems are underconstrained by what you do with
them. 
Nagel would argue that even if we rationally understand the
*umwelt*, that does not render the experience commensurable.
There is an internal aspect our model cannot capture.

I suspect the truth is somewhere in between.
If we could understand all the relevant carriers of meaning, but more
subtly, the *ways they are encoded and manipulated by the interface*,
I think we would be a good deal closer to understanding what it is
like to be a bat.
These are in principle discoverable by neuroscience, but not zoology.
That said, there is probably a gestalt aspect to *operating the
interface* which understanding all its parts does not give.
This is, roughly speaking, the distinction between
["knowing how" and "knowing that"](https://plato.stanford.edu/entries/knowledge-how/).
And at a cognitive level, there is no conceivable sequence of Hebbian changes
that will turn me into a bat. -->

<!-- #### Alien brain, alien mind?

Incommensurability has implications for extraterrestrial life.
From the
[Voyager record](https://en.wikipedia.org/wiki/Voyager_Golden_Record)
to [SETI@home](https://setiathome.berkeley.edu/), efforts to talk to
aliens represent experiments in cognitive relativism.
The question they pose is: could  develop convergently?

[Convergent evolution](https://en.wikipedia.org/wiki/Convergent_evolution)
occurs when phylogenetically distant organisms converge on similar
solutions to similar problems.
The most famous example is the eye, where vertebrates and cephalopods
evolved the same biological camera from the single photoreceptive
pixel of their most recent common ancestor.

<!-- Despite all this talk of generic non-uniqueness, I think that
commensurability is probably an empirical question.
If so, the simplest way to phrase cognitive relativism is that
mind [supervenes](https://plato.stanford.edu/entries/supervenience/) on the
brain: no experiential difference without a brain difference, though
the converse need not hold.
Supervenience of mind on brain is weaker than strict identification,
and gives ontological wiggle room for Nagelian phenomenology (if one
is so inclined), while allowing for the possibility that the same sort
of mind could arise from different sorts of brain.
Similar minds would be commensurable. -->

<!-- There are biological precedents for this idea.
[Convergent evolution](https://en.wikipedia.org/wiki/Convergent_evolution)
occurs when phylogenetically distant organisms converge on similar
solutions to similar problems.
The most famous example is the eye, where vertebrates and cephalopods
evolved the same biological camera from the single photoreceptive
pixel of their most recent common ancestor.
Could mind also develop convergently?
Though it sounds like a dusty quibble, this question is
central to our search for extraterrestrial life!
From the
[Voyager record](https://en.wikipedia.org/wiki/Voyager_Golden_Record)
to [SETI@home](https://setiathome.berkeley.edu/), efforts to talk to
aliens represent experiements in cognitive relativism. 

When *umwelten* overlap, Estonian semoiotician Yuri Lotman proposed
that a ["semiosphere"](https://en.wikipedia.org/wiki/Semiosphere)
results: a realm of shared meaning that arises by virtue of shared
"marks".
For instance, I think humans enjoy the company of dogs, and vice
versa, due to a generous overlap of *umwelten*.
Many of their pleasures are our pleasures (though by no means all,
as frolicking in carrion shows).
To establish meaningful connection with an alien mind, the semiosphere
cannot be empty.

The possibilities for radical differences in alien culture and biology
are part of an
[established set of tropes](https://tvtropes.org/pmwiki/pmwiki.php/Main/AlienTropes).
But in the same way that an intraspecific universalist can fall back
on the bedrock of conition to ground translation and intercultural
dialogue, science fiction often falls back on the bedrock of reality
to ground interspecific dialogue.
We may find the tentacles offputting and the customs bizarre, but we
can always talk about gravity and prime numbers instead. -->

<!-- Sometimes, intelligence is lumped into the same category as the eye. But while the camera eye can be described in a sentence---light
passses through a pinhole onto a photoreceptive screen---there is no
simple definition of intelligence current among biologists. --> 

<!-- Let's leave the problem
The natural yardstick for incommensurability is phylogenetic.
The further away you look on the Tree of Life, the greater the
imaginative obstructions, the more exotic the sensory modalities and
carriers of meaning, the more radically different the *umwelten*.
A bat is not "fundamentally alien".
It is a mammal, so we share large chunks of brain function and DNA.
But what if we were to encounter beings from a different Tree altogether?
I would place a very high prior on incommensurability of some sort. -->

<!-- http://www.hutter1.net/ai/uaibook.htm -->

<!-- And it seems like the incomparability between these strange -->
<!-- organisms would be pairwise mutual. An anglerfish and a bat have -->
<!-- about as much in common as a bat and an anglerfish and a human. But there is a whole class -->
<!-- The more pronounced the imaginative obstructions, the more plausible
strong cognitive relativism seems.
But when we look nearby on the Tree of Life, it becomes less so.
I doubt I can simulate an anglerfish, but what about a chimpanzee?
There are no exotic sensory modalities a Nagelian could use as proof
of incommensurability. In fact, their brain is almost identical to
ours. -->
<!-- A human child raised by chimpanzees would probably have the same
gestalt experience as a chimpanzee, and the imaginative obstructions
to human adults are more likely neuroplastic than fundamentally
cognitive. -->
<!-- This is *consistent* with strong cognitive relativism, 
finessed to take cognitive similarity into account.
Similar brains lead to similar realities, so incommensurability itself
is a relative affair.
But there -->
